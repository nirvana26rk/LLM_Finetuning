{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyPXoMyD4t3YkHoxPjEdZgoZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"063bdd1001174dd2860fb833f11e1935":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e42abceb026d464ca7fa2d7453203b17","IPY_MODEL_d87ad2a2b08043dd921b2c0e059824f5","IPY_MODEL_1b0ae2e5d2364df0bf7321ff69a00afa"],"layout":"IPY_MODEL_5393724f40794e4c8fc21ba52ebbf3b4"}},"e42abceb026d464ca7fa2d7453203b17":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bacf429114e740a2b2cbac9bc2eafac4","placeholder":"​","style":"IPY_MODEL_63da59da95584361a0b0a48b0918d8bd","value":"Loading checkpoint shards: 100%"}},"d87ad2a2b08043dd921b2c0e059824f5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e3e627670484976b60907551df0cc0f","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_31fbc8a39e1043698d4d2fb920aa8c72","value":2}},"1b0ae2e5d2364df0bf7321ff69a00afa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa68458c97fa459695eb757a4c30d11b","placeholder":"​","style":"IPY_MODEL_1b3a67cde6d147bbacbf1e56227ec8a5","value":" 2/2 [00:05&lt;00:00,  2.74s/it]"}},"5393724f40794e4c8fc21ba52ebbf3b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bacf429114e740a2b2cbac9bc2eafac4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63da59da95584361a0b0a48b0918d8bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8e3e627670484976b60907551df0cc0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31fbc8a39e1043698d4d2fb920aa8c72":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fa68458c97fa459695eb757a4c30d11b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b3a67cde6d147bbacbf1e56227ec8a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1dd79c8397a44d4e9aa2e324d1e4a2b8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_943f8f5a3ce24209aecfc17e2ab03a99","IPY_MODEL_a8f3b59ad9f14efb87a12bb8f830dc37","IPY_MODEL_0fe8649e624a4473b4898cef04d9ea9e"],"layout":"IPY_MODEL_95ff9a0b117345e79fbe54c0efda2c84"}},"943f8f5a3ce24209aecfc17e2ab03a99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7bcd00682d94a6cbfa8f2131ac9539e","placeholder":"​","style":"IPY_MODEL_e5512463d4194fc48df6bf65f3d7ec48","value":"Map: 100%"}},"a8f3b59ad9f14efb87a12bb8f830dc37":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ae81ed8bc3d411d96d94ed48069cff0","max":4370,"min":0,"orientation":"horizontal","style":"IPY_MODEL_743830c946834ff499cead56f76f4996","value":4370}},"0fe8649e624a4473b4898cef04d9ea9e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0eaeca7a8e3345bb8e59da7915b58ea1","placeholder":"​","style":"IPY_MODEL_2d7a4ecbc093407c8d1acffe2c8b85a6","value":" 4370/4370 [00:05&lt;00:00, 873.72 examples/s]"}},"95ff9a0b117345e79fbe54c0efda2c84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7bcd00682d94a6cbfa8f2131ac9539e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5512463d4194fc48df6bf65f3d7ec48":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3ae81ed8bc3d411d96d94ed48069cff0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"743830c946834ff499cead56f76f4996":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0eaeca7a8e3345bb8e59da7915b58ea1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d7a4ecbc093407c8d1acffe2c8b85a6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c78654b2a48247dd80c70c4503e91308":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_95acc05173a94c908bebebce3d2c7001","IPY_MODEL_a698b506e7fa4586ad3fc97d051a4b50","IPY_MODEL_beb6bd673b48427ea09333e4912c369d"],"layout":"IPY_MODEL_de3aa39e57b743809ef634392e0949dd"}},"95acc05173a94c908bebebce3d2c7001":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_88a991dcdd4c4425a0919848f7db5371","placeholder":"​","style":"IPY_MODEL_ac0ff57fab8047149822a72907efa726","value":"Map: 100%"}},"a698b506e7fa4586ad3fc97d051a4b50":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf088d8a4f724a7290667ae914b16aac","max":1873,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bf9407f7eff242c587af406956e2b40d","value":1873}},"beb6bd673b48427ea09333e4912c369d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0de84fa625a74097a6f829d0eed76bc1","placeholder":"​","style":"IPY_MODEL_bc12cbf6ecfc4dd29baeb2168f38a928","value":" 1873/1873 [00:02&lt;00:00, 859.38 examples/s]"}},"de3aa39e57b743809ef634392e0949dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88a991dcdd4c4425a0919848f7db5371":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac0ff57fab8047149822a72907efa726":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf088d8a4f724a7290667ae914b16aac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf9407f7eff242c587af406956e2b40d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0de84fa625a74097a6f829d0eed76bc1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc12cbf6ecfc4dd29baeb2168f38a928":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98c0cb39ea9f4f719fccd1472ebc599e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9b6483098ab34a12bf4203fb3c0f3b26","IPY_MODEL_5f72caca4411420aae47e8be44cfa46e","IPY_MODEL_f5c322cdee064a298b0d45a3e74f3a9d"],"layout":"IPY_MODEL_799bb9bec3b94df7adb78bcac4a7853e"}},"9b6483098ab34a12bf4203fb3c0f3b26":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c00817e3b2d04889b7f4ca787413173e","placeholder":"​","style":"IPY_MODEL_35fd9c25fd224288a7bba7d8004ad799","value":"Epoch 1:   0%"}},"5f72caca4411420aae47e8be44cfa46e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_31f8b64a75014c718f97e8ece2d39376","max":1093,"min":0,"orientation":"horizontal","style":"IPY_MODEL_46a5729e900e4acfb556dd9302bb23e0","value":0}},"f5c322cdee064a298b0d45a3e74f3a9d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1345754ab07740e38f286960bafd750d","placeholder":"​","style":"IPY_MODEL_a47d53f1953e4a8d824eb5a4acee0d8a","value":" 0/1093 [00:04&lt;?, ?it/s]"}},"799bb9bec3b94df7adb78bcac4a7853e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c00817e3b2d04889b7f4ca787413173e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35fd9c25fd224288a7bba7d8004ad799":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31f8b64a75014c718f97e8ece2d39376":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46a5729e900e4acfb556dd9302bb23e0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1345754ab07740e38f286960bafd750d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a47d53f1953e4a8d824eb5a4acee0d8a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FQBe_z3LJG8R","executionInfo":{"status":"ok","timestamp":1727579253744,"user_tz":-480,"elapsed":41449,"user":{"displayName":"Kunal R R","userId":"08771470267005146834"}},"outputId":"db8d43cf-bfcf-47c5-87b9-234de8b5496f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n","Collecting datasets\n","  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n","Collecting bitsandbytes\n","  Downloading bitsandbytes-0.44.0-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\n","Collecting peft\n","  Downloading peft-0.13.0-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n","Collecting pyarrow>=15.0.0 (from datasets)\n","  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.4.1+cu121)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n","Downloading datasets-3.0.1-py3-none-any.whl (471 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bitsandbytes-0.44.0-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading peft-0.13.0-py3-none-any.whl (322 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.5/322.5 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, pyarrow, dill, multiprocess, bitsandbytes, peft, datasets\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 14.0.2\n","    Uninstalling pyarrow-14.0.2:\n","      Successfully uninstalled pyarrow-14.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed bitsandbytes-0.44.0 datasets-3.0.1 dill-0.3.8 multiprocess-0.70.16 peft-0.13.0 pyarrow-17.0.0 xxhash-3.5.0\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n","Collecting evaluate\n","  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n","Collecting flash-attn\n","  Downloading flash_attn-2.6.3.tar.gz (2.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting wandb\n","  Downloading wandb-0.18.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.0.1)\n","Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.1.4)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.24.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from flash-attn) (0.8.0)\n","Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n","Collecting docker-pycreds>=0.4.0 (from wandb)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n","Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n","  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n","Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n","Collecting sentry-sdk>=1.0.0 (from wandb)\n","  Downloading sentry_sdk-2.14.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting setproctitle (from wandb)\n","  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.5)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n","  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.11.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n","  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n","Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading wandb-0.18.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sentry_sdk-2.14.0-py2.py3-none-any.whl (311 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.4/311.4 kB\u001b[0m \u001b[31m384.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: flash-attn\n","  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for flash-attn: filename=flash_attn-2.6.3-cp310-cp310-linux_x86_64.whl size=187309225 sha256=237ef9c6157db394e1ddde4ba609a21ebb98382377a27041edc09318801a6f24\n","  Stored in directory: /root/.cache/pip/wheels/7e/e3/c3/89c7a2f3c4adc07cd1c675f8bb7b9ad4d18f64a72bccdfe826\n","Successfully built flash-attn\n","Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, flash-attn, wandb, evaluate\n","Successfully installed docker-pycreds-0.4.0 evaluate-0.4.3 flash-attn-2.6.3 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.14.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.18.2\n"]}],"source":["# Install required libraries\n","!pip install transformers datasets bitsandbytes accelerate peft\n","!pip install scikit-learn torch evaluate flash-attn wandb"]},{"cell_type":"code","source":[],"metadata":{"id":"ak1o9U_OJQ7w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments\n","from peft import get_peft_model, LoraConfig, TaskType\n","from datasets import Dataset\n","from sklearn.model_selection import train_test_split\n","import json\n","import hashlib\n","import wandb\n","import logging\n","import warnings\n","from torch.utils.data import DataLoader\n","from tqdm.auto import tqdm\n","\n","warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"torch.utils.checkpoint\")\n"],"metadata":{"id":"OGa2LmBZJRGX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Uup-CRUMJsSI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Data loading and processing functions\n","def load_jsonl(path):\n","    with open(path, 'r') as file:\n","        return [json.loads(line) for line in file]\n","\n","def format_ultrachat_data(data):\n","    formatted_data = []\n","    for item in data:\n","        text = item['text']\n","        query_start = text.find(\"### Query:\") + len(\"### Query:\")\n","        response_start = text.find(\"### Response:\") + len(\"### Response:\")\n","        references_start = text.find(\"### References:\") + len(\"### References:\")\n","\n","        query = text[query_start:response_start - len(\"### Response:\")].strip()\n","        response = text[response_start:references_start - len(\"### References:\")].strip()\n","\n","        prompt_id = hashlib.sha256(query.encode()).hexdigest()\n","\n","        formatted_item = {\n","            \"prompt\": query,\n","            \"prompt_id\": prompt_id,\n","            \"messages\": [\n","                {\"content\": query, \"role\": \"user\"},\n","                {\"content\": response, \"role\": \"assistant\"}\n","            ]\n","        }\n","        formatted_data.append(formatted_item)\n","    return formatted_data\n","\n","def collate_and_tokenize(examples, tokenizer, max_length):\n","    texts = [\" \".join([msg['content'] for msg in example['messages']]) for example in examples['data']]\n","\n","    encoded = tokenizer(\n","        texts,\n","        padding=\"max_length\",\n","        truncation=True,\n","        max_length=max_length,\n","        return_tensors=\"pt\"\n","    )\n","\n","    encoded['labels'] = encoded['input_ids'].clone()\n","    return encoded\n","\n","def prepare_datasets(data_path, tokenizer, max_length=2048):\n","    try:\n","        data = load_jsonl(data_path)\n","    except FileNotFoundError:\n","        raise FileNotFoundError(f\"The file {data_path} was not found. Please check the file path and try again.\")\n","\n","    if not data:\n","        raise ValueError(f\"The file {data_path} is empty or could not be read properly.\")\n","\n","    train_data, test_data = train_test_split(data, test_size=0.3, random_state=42)\n","\n","    train_data_formatted = format_ultrachat_data(train_data)\n","    test_data_formatted = format_ultrachat_data(test_data)\n","\n","    train_dataset = Dataset.from_dict({\"data\": train_data_formatted})\n","    test_dataset = Dataset.from_dict({\"data\": test_data_formatted})\n","\n","    print(f\"Dataset size - Train: {len(train_dataset)}, Test: {len(test_dataset)}\")\n","\n","    tokenized_train = train_dataset.map(\n","        lambda examples: collate_and_tokenize(examples, tokenizer, max_length),\n","        batched=True,\n","        remove_columns=train_dataset.column_names\n","    )\n","    tokenized_test = test_dataset.map(\n","        lambda examples: collate_and_tokenize(examples, tokenizer, max_length),\n","        batched=True,\n","        remove_columns=test_dataset.column_names\n","    )\n","\n","    return tokenized_train, tokenized_test\n","\n"],"metadata":{"id":"1kImFAkqJseB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n","from peft import get_peft_model, LoraConfig, TaskType\n","from torch.utils.data import DataLoader\n","from tqdm.auto import tqdm\n","\n","# Model and tokenizer setup\n","model_name = \"microsoft/Phi-3.5-mini-instruct\"\n","\n","# Quantization config\n","quantization_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_compute_dtype=torch.float16,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\"\n",")\n","\n","# Load model\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    quantization_config=quantization_config,\n","    device_map=\"auto\",\n","    trust_remote_code=True\n",")\n","\n","# Load tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.padding_side = \"right\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["063bdd1001174dd2860fb833f11e1935","e42abceb026d464ca7fa2d7453203b17","d87ad2a2b08043dd921b2c0e059824f5","1b0ae2e5d2364df0bf7321ff69a00afa","5393724f40794e4c8fc21ba52ebbf3b4","bacf429114e740a2b2cbac9bc2eafac4","63da59da95584361a0b0a48b0918d8bd","8e3e627670484976b60907551df0cc0f","31fbc8a39e1043698d4d2fb920aa8c72","fa68458c97fa459695eb757a4c30d11b","1b3a67cde6d147bbacbf1e56227ec8a5"]},"id":"Y5HH1tG_J6H3","executionInfo":{"status":"ok","timestamp":1727375353586,"user_tz":-480,"elapsed":7774,"user":{"displayName":"Kunal R R","userId":"08771470267005146834"}},"outputId":"19e88ea3-bcce-43cd-a973-8a1685bd8ff6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0/config.json\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0/config.json\n","Model config Phi3Config {\n","  \"_name_or_path\": \"microsoft/Phi-3.5-mini-instruct\",\n","  \"architectures\": [\n","    \"Phi3ForCausalLM\"\n","  ],\n","  \"attention_bias\": false,\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"microsoft/Phi-3.5-mini-instruct--configuration_phi3.Phi3Config\",\n","    \"AutoModelForCausalLM\": \"microsoft/Phi-3.5-mini-instruct--modeling_phi3.Phi3ForCausalLM\"\n","  },\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": 32000,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 3072,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"max_position_embeddings\": 131072,\n","  \"model_type\": \"phi3\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 32,\n","  \"num_key_value_heads\": 32,\n","  \"original_max_position_embeddings\": 4096,\n","  \"pad_token_id\": 32000,\n","  \"resid_pdrop\": 0.0,\n","  \"rms_norm_eps\": 1e-05,\n","  \"rope_scaling\": {\n","    \"long_factor\": [\n","      1.0800000429153442,\n","      1.1100000143051147,\n","      1.1399999856948853,\n","      1.340000033378601,\n","      1.5899999141693115,\n","      1.600000023841858,\n","      1.6200000047683716,\n","      2.620000123977661,\n","      3.2300000190734863,\n","      3.2300000190734863,\n","      4.789999961853027,\n","      7.400000095367432,\n","      7.700000286102295,\n","      9.09000015258789,\n","      12.199999809265137,\n","      17.670000076293945,\n","      24.46000099182129,\n","      28.57000160217285,\n","      30.420001983642578,\n","      30.840002059936523,\n","      32.590003967285156,\n","      32.93000411987305,\n","      42.320003509521484,\n","      44.96000289916992,\n","      50.340003967285156,\n","      50.45000457763672,\n","      57.55000305175781,\n","      57.93000411987305,\n","      58.21000289916992,\n","      60.1400032043457,\n","      62.61000442504883,\n","      62.62000274658203,\n","      62.71000289916992,\n","      63.1400032043457,\n","      63.1400032043457,\n","      63.77000427246094,\n","      63.93000411987305,\n","      63.96000289916992,\n","      63.970001220703125,\n","      64.02999877929688,\n","      64.06999969482422,\n","      64.08000183105469,\n","      64.12000274658203,\n","      64.41000366210938,\n","      64.4800033569336,\n","      64.51000213623047,\n","      64.52999877929688,\n","      64.83999633789062\n","    ],\n","    \"short_factor\": [\n","      1.0,\n","      1.0199999809265137,\n","      1.0299999713897705,\n","      1.0299999713897705,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0499999523162842,\n","      1.0699999332427979,\n","      1.0999999046325684,\n","      1.1099998950958252,\n","      1.1599998474121094,\n","      1.1599998474121094,\n","      1.1699998378753662,\n","      1.2899998426437378,\n","      1.339999794960022,\n","      1.679999828338623,\n","      1.7899998426437378,\n","      1.8199998140335083,\n","      1.8499997854232788,\n","      1.8799997568130493,\n","      1.9099997282028198,\n","      1.9399996995925903,\n","      1.9899996519088745,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0199997425079346,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0299997329711914,\n","      2.0799996852874756,\n","      2.0899996757507324,\n","      2.189999580383301,\n","      2.2199995517730713,\n","      2.5899994373321533,\n","      2.729999542236328,\n","      2.749999523162842,\n","      2.8399994373321533\n","    ],\n","    \"type\": \"longrope\"\n","  },\n","  \"rope_theta\": 10000.0,\n","  \"sliding_window\": 262144,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.44.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32064\n","}\n","\n","Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass torch_dtype=torch.float16 to remove this warning.\n","loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0/model.safetensors.index.json\n","Instantiating Phi3ForCausalLM model under default dtype torch.float16.\n","Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 32000,\n","  \"pad_token_id\": 32000\n","}\n","\n","target_dtype {target_dtype} is replaced by `CustomDtype.INT4` for 4-bit BnB quantization\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"063bdd1001174dd2860fb833f11e1935"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["All model checkpoint weights were used when initializing Phi3ForCausalLM.\n","\n","All the weights of Phi3ForCausalLM were initialized from the model checkpoint at microsoft/Phi-3.5-mini-instruct.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use Phi3ForCausalLM for predictions without further training.\n","loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0/generation_config.json\n","Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": [\n","    32007,\n","    32001,\n","    32000\n","  ],\n","  \"pad_token_id\": 32000\n","}\n","\n","loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0/tokenizer.model\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0/tokenizer.json\n","loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0/added_tokens.json\n","loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0/special_tokens_map.json\n","loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3.5-mini-instruct/snapshots/af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0/tokenizer_config.json\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"UX5xmMclJ614"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# LoRA configuration\n","peft_config = LoraConfig(\n","    task_type=TaskType.CAUSAL_LM,\n","    r=16,\n","    lora_alpha=32,\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    target_modules=[\n","        \"self_attn.o_proj\",\n","        \"self_attn.qkv_proj\",\n","        \"mlp.gate_up_proj\",\n","        \"mlp.down_proj\",\n","    ]\n",")\n","\n","# Wrap the model with LoRA\n","model = get_peft_model(model, peft_config)\n","\n","# Ensure only LoRA parameters are trainable\n","for name, param in model.named_parameters():\n","    if \"lora\" in name:\n","        param.requires_grad = True\n","    else:\n","        param.requires_grad = False\n","\n","# Prepare optimizer\n","optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n","\n","# Training loop\n","def train(model, train_dataloader, optimizer, num_epochs=3):\n","    device = next(model.parameters()).device\n","    model.train()\n","\n","    for epoch in range(num_epochs):\n","        total_loss = 0\n","        for batch in tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}\"):\n","            batch = {k: v.to(device) for k, v in batch.items()}\n","\n","            optimizer.zero_grad()\n","\n","            outputs = model(**batch)\n","            loss = outputs.loss\n","            total_loss += loss.item()\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","        print(f\"Epoch {epoch + 1}, Average loss: {total_loss / len(train_dataloader)}\")"],"metadata":{"id":"5rsudgeYmHDW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from peft import get_peft_model, LoraConfig, TaskType\n","import torch\n","\n","# Define QLoRA Config\n","lora_config = LoraConfig(\n","    r=32,\n","    lora_alpha=32,\n","    target_modules=[\n","        \"self_attn.o_proj\",\n","        \"self_attn.qkv_proj\",\n","        \"mlp.gate_up_proj\",\n","        \"mlp.down_proj\",\n","    ],\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\"\n",")\n","\n","# Get PEFT model\n","lora_model = get_peft_model(model, lora_config)\n","\n","# Function to print trainable parameters\n","def print_trainable_parameters(model):\n","    trainable_params = 0\n","    all_param = 0\n","    for name, param in model.named_parameters():\n","        all_param += param.numel()\n","        if param.requires_grad:\n","            trainable_params += param.numel()\n","        print(f\"Parameter: {name}, Shape: {param.shape}, Requires Grad: {param.requires_grad}, dtype: {param.dtype}\")\n","    print(f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\")\n","\n","# Print information about the model parameters\n","print_trainable_parameters(lora_model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1oRQSuWKVXnA","executionInfo":{"status":"ok","timestamp":1727371135704,"user_tz":-480,"elapsed":1308,"user":{"displayName":"Kunal R R","userId":"08771470267005146834"}},"outputId":"876acbf3-d540-43b0-dbe5-c22a78ee21fb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Parameter: base_model.model.model.embed_tokens.weight, Shape: torch.Size([32064, 3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.0.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.0.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.0.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.0.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.0.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.0.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.0.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.0.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.0.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.1.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.1.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.1.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.1.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.1.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.1.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.1.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.1.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.1.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.2.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.2.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.2.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.2.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.2.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.2.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.2.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.2.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.2.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.3.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.3.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.3.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.3.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.3.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.3.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.3.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.3.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.3.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.4.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.4.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.4.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.4.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.4.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.4.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.4.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.4.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.4.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.5.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.5.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.5.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.5.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.5.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.5.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.5.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.5.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.5.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.6.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.6.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.6.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.6.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.6.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.6.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.6.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.6.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.6.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.7.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.7.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.7.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.7.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.7.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.7.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.7.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.7.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.7.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.8.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.8.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.8.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.8.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.8.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.8.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.8.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.8.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.8.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.9.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.9.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.9.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.9.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.9.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.9.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.9.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.9.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.9.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.10.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.10.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.10.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.10.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.10.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.10.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.10.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.10.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.10.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.11.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.11.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.11.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.11.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.11.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.11.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.11.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.11.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.11.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.12.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.12.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.12.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.12.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.12.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.12.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.12.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.12.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.12.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.13.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.13.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.13.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.13.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.13.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.13.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.13.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.13.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.13.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.14.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.14.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.14.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.14.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.14.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.14.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.14.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.14.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.14.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.15.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.15.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.15.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.15.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.15.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.15.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.15.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.15.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.15.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.16.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.16.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.16.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.16.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.16.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.16.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.16.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.16.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.16.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.17.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.17.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.17.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.17.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.17.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.17.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.17.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.17.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.17.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.18.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.18.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.18.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.18.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.18.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.18.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.18.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.18.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.18.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.19.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.19.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.19.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.19.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.19.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.19.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.19.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.19.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.19.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.20.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.20.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.20.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.20.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.20.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.20.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.20.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.20.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.20.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.21.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.21.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.21.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.21.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.21.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.21.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.21.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.21.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.21.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.22.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.22.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.22.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.22.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.22.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.22.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.22.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.22.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.22.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.23.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.23.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.23.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.23.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.23.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.23.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.23.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.23.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.23.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.24.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.24.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.24.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.24.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.24.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.24.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.24.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.24.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.24.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.24.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.25.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.25.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.25.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.25.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.25.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.25.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.25.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.25.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.25.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.25.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.26.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.26.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.26.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.26.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.26.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.26.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.26.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.26.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.26.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.26.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.27.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.27.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.27.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.27.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.27.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.27.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.27.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.27.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.27.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.27.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.28.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.28.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.28.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.28.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.28.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.28.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.28.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.28.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.28.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.28.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.28.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.29.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.29.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.29.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.29.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.29.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.29.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.29.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.29.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.29.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.29.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.29.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.30.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.30.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.30.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.30.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.30.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.30.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.30.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.30.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.30.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.30.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.30.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.31.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.31.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.31.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.31.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.31.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.31.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.31.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.31.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.31.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.31.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.31.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.norm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.lm_head.weight, Shape: torch.Size([32064, 3072]), Requires Grad: False, dtype: torch.float16\n","trainable params: 50331648 || all params: 2059471872 || trainable%: 2.44\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"8uKMbEQyVXxR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ensure only appropriate parameters require gradients\n","for name, param in lora_model.named_parameters():\n","    if 'lora' in name:  # Only LoRA parameters should be trainable\n","        param.requires_grad = True\n","    else:\n","        param.requires_grad = False\n","\n","print(\"\\nAfter setting requires_grad:\")\n","print_trainable_parameters(lora_model)\n","\n","# Prepare the model for training\n","lora_model.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cOmYFdFhVX5g","executionInfo":{"status":"ok","timestamp":1727371180834,"user_tz":-480,"elapsed":566,"user":{"displayName":"Kunal R R","userId":"08771470267005146834"}},"outputId":"553b82db-cc3e-4c06-ace3-3c26423c6759"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","After setting requires_grad:\n","Parameter: base_model.model.model.embed_tokens.weight, Shape: torch.Size([32064, 3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.0.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.0.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.0.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.0.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.0.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.0.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.0.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.0.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.0.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.1.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.1.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.1.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.1.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.1.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.1.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.1.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.1.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.1.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.2.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.2.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.2.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.2.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.2.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.2.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.2.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.2.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.2.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.3.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.3.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.3.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.3.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.3.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.3.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.3.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.3.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.3.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.4.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.4.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.4.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.4.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.4.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.4.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.4.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.4.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.4.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.5.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.5.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.5.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.5.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.5.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.5.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.5.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.5.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.5.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.6.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.6.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.6.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.6.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.6.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.6.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.6.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.6.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.6.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.7.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.7.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.7.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.7.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.7.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.7.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.7.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.7.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.7.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.8.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.8.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.8.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.8.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.8.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.8.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.8.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.8.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.8.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.9.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.9.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.9.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.9.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.9.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.9.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.9.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.9.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.9.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.10.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.10.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.10.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.10.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.10.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.10.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.10.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.10.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.10.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.11.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.11.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.11.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.11.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.11.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.11.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.11.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.11.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.11.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.12.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.12.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.12.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.12.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.12.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.12.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.12.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.12.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.12.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.13.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.13.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.13.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.13.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.13.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.13.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.13.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.13.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.13.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.14.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.14.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.14.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.14.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.14.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.14.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.14.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.14.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.14.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.15.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.15.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.15.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.15.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.15.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.15.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.15.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.15.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.15.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.16.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.16.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.16.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.16.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.16.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.16.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.16.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.16.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.16.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.17.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.17.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.17.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.17.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.17.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.17.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.17.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.17.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.17.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.18.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.18.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.18.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.18.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.18.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.18.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.18.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.18.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.18.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.19.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.19.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.19.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.19.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.19.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.19.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.19.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.19.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.19.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.20.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.20.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.20.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.20.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.20.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.20.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.20.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.20.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.20.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.21.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.21.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.21.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.21.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.21.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.21.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.21.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.21.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.21.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.22.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.22.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.22.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.22.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.22.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.22.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.22.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.22.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.22.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.23.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.23.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.23.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.23.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.23.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.23.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.23.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.23.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.23.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.24.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.24.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.24.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.24.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.24.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.24.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.24.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.24.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.24.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.24.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.25.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.25.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.25.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.25.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.25.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.25.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.25.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.25.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.25.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.25.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.26.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.26.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.26.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.26.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.26.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.26.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.26.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.26.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.26.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.26.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.27.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.27.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.27.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.27.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.27.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.27.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.27.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.27.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.27.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.27.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.28.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.28.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.28.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.28.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.28.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.28.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.28.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.28.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.28.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.28.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.28.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.28.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.28.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.29.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.29.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.29.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.29.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.29.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.29.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.29.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.29.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.29.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.29.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.29.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.29.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.29.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.30.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.30.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.30.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.30.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.30.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.30.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.30.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.30.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.30.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.30.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.30.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.30.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.30.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.31.self_attn.o_proj.base_layer.weight, Shape: torch.Size([4718592, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.31.self_attn.o_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.31.self_attn.o_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.31.self_attn.qkv_proj.base_layer.weight, Shape: torch.Size([14155776, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.31.self_attn.qkv_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.31.self_attn.qkv_proj.lora_B.default.weight, Shape: torch.Size([9216, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.31.mlp.gate_up_proj.base_layer.weight, Shape: torch.Size([25165824, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.31.mlp.gate_up_proj.lora_A.default.weight, Shape: torch.Size([32, 3072]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.31.mlp.gate_up_proj.lora_B.default.weight, Shape: torch.Size([16384, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.31.mlp.down_proj.base_layer.weight, Shape: torch.Size([12582912, 1]), Requires Grad: False, dtype: torch.uint8\n","Parameter: base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight, Shape: torch.Size([32, 8192]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.31.mlp.down_proj.lora_B.default.weight, Shape: torch.Size([3072, 32]), Requires Grad: True, dtype: torch.float32\n","Parameter: base_model.model.model.layers.31.input_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.layers.31.post_attention_layernorm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.model.norm.weight, Shape: torch.Size([3072]), Requires Grad: False, dtype: torch.float16\n","Parameter: base_model.model.lm_head.weight, Shape: torch.Size([32064, 3072]), Requires Grad: False, dtype: torch.float16\n","trainable params: 50331648 || all params: 2059471872 || trainable%: 2.44\n"]},{"output_type":"execute_result","data":{"text/plain":["PeftModelForCausalLM(\n","  (base_model): LoraModel(\n","    (model): Phi3ForCausalLM(\n","      (model): Phi3Model(\n","        (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n","        (embed_dropout): Dropout(p=0.0, inplace=False)\n","        (layers): ModuleList(\n","          (0-31): 32 x Phi3DecoderLayer(\n","            (self_attn): Phi3Attention(\n","              (o_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=3072, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=3072, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (qkv_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=3072, out_features=9216, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=3072, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=9216, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (rotary_emb): Phi3LongRoPEScaledRotaryEmbedding()\n","            )\n","            (mlp): Phi3MLP(\n","              (gate_up_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=3072, out_features=16384, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=3072, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=16384, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (down_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=8192, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=3072, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (activation_fn): SiLU()\n","            )\n","            (input_layernorm): Phi3RMSNorm()\n","            (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n","            (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n","            (post_attention_layernorm): Phi3RMSNorm()\n","          )\n","        )\n","        (norm): Phi3RMSNorm()\n","      )\n","      (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":[],"metadata":{"id":"gvSvgs8sVX9x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Prepare datasets\n","train_dataset, test_dataset = prepare_datasets(\"combined_UnitOps_Training_ZAR.jsonl\", tokenizer, max_length=2048)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":98,"referenced_widgets":["1dd79c8397a44d4e9aa2e324d1e4a2b8","943f8f5a3ce24209aecfc17e2ab03a99","a8f3b59ad9f14efb87a12bb8f830dc37","0fe8649e624a4473b4898cef04d9ea9e","95ff9a0b117345e79fbe54c0efda2c84","f7bcd00682d94a6cbfa8f2131ac9539e","e5512463d4194fc48df6bf65f3d7ec48","3ae81ed8bc3d411d96d94ed48069cff0","743830c946834ff499cead56f76f4996","0eaeca7a8e3345bb8e59da7915b58ea1","2d7a4ecbc093407c8d1acffe2c8b85a6","c78654b2a48247dd80c70c4503e91308","95acc05173a94c908bebebce3d2c7001","a698b506e7fa4586ad3fc97d051a4b50","beb6bd673b48427ea09333e4912c369d","de3aa39e57b743809ef634392e0949dd","88a991dcdd4c4425a0919848f7db5371","ac0ff57fab8047149822a72907efa726","cf088d8a4f724a7290667ae914b16aac","bf9407f7eff242c587af406956e2b40d","0de84fa625a74097a6f829d0eed76bc1","bc12cbf6ecfc4dd29baeb2168f38a928"]},"id":"wKQm-P3YVYfZ","executionInfo":{"status":"ok","timestamp":1727371317662,"user_tz":-480,"elapsed":8093,"user":{"displayName":"Kunal R R","userId":"08771470267005146834"}},"outputId":"2555c3f3-3435-4b9e-d94d-12b44ff0e22c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset size - Train: 4370, Test: 1873\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/4370 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1dd79c8397a44d4e9aa2e324d1e4a2b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1873 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c78654b2a48247dd80c70c4503e91308"}},"metadata":{}}]},{"cell_type":"code","source":["# Initialize wandb\n","wandb.init(project=\"DataScience_CapStone\", entity=\"kunalraghuvanshi-the-university-of-western-australia\")\n","\n","# Training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./phi3_5_mini_instruct_qlora_chemical_eng\",\n","    num_train_epochs=5,\n","    per_device_train_batch_size=4,\n","    per_device_eval_batch_size=4,\n","    gradient_accumulation_steps=8,\n","    learning_rate=1e-4,\n","    weight_decay=0.01,\n","    warmup_ratio=0.03,\n","    lr_scheduler_type=\"cosine\",\n","    logging_dir='./logs',\n","    logging_steps=1,\n","    save_strategy=\"steps\",\n","    save_steps=100,\n","    evaluation_strategy=\"steps\",\n","    eval_steps=100,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"loss\",\n","    greater_is_better=False,\n","    fp16=True,\n","    max_grad_norm=0.3,\n","    report_to=[\"wandb\"],\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":280},"id":"EeekfyHqWuVZ","executionInfo":{"status":"ok","timestamp":1727371513696,"user_tz":-480,"elapsed":164212,"user":{"displayName":"Kunal R R","userId":"08771470267005146834"}},"outputId":"b1b0a4ea-7052-44a4-9371-2fc26e8e864b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":[" ··········\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.18.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20240926_172510-qa5379g8</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/kunalraghuvanshi-the-university-of-western-australia/DataScience_CapStone/runs/qa5379g8' target=\"_blank\">visionary-dawn-2</a></strong> to <a href='https://wandb.ai/kunalraghuvanshi-the-university-of-western-australia/DataScience_CapStone' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/kunalraghuvanshi-the-university-of-western-australia/DataScience_CapStone' target=\"_blank\">https://wandb.ai/kunalraghuvanshi-the-university-of-western-australia/DataScience_CapStone</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/kunalraghuvanshi-the-university-of-western-australia/DataScience_CapStone/runs/qa5379g8' target=\"_blank\">https://wandb.ai/kunalraghuvanshi-the-university-of-western-australia/DataScience_CapStone/runs/qa5379g8</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","PyTorch: setting up devices\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"nduTfXVTWuhC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Data collator\n","def data_collator(examples):\n","    return tokenizer.pad(examples, padding=True, return_tensors=\"pt\")\n","\n","# Setup DataLoader\n","train_dataloader = DataLoader(\n","    train_dataset,\n","    batch_size=training_args.per_device_train_batch_size,\n","    shuffle=True,\n","    collate_fn=data_collator\n",")\n","\n","eval_dataloader = DataLoader(\n","    test_dataset,\n","    batch_size=training_args.per_device_eval_batch_size,\n","    collate_fn=data_collator\n",")\n","\n","# Prepare optimizer\n","optimizer = torch.optim.AdamW(lora_model.parameters(), lr=training_args.learning_rate)\n","\n","# Training loop\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","lora_model.to(device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F4qLIQXFWulg","executionInfo":{"status":"ok","timestamp":1727371675861,"user_tz":-480,"elapsed":750,"user":{"displayName":"Kunal R R","userId":"08771470267005146834"}},"outputId":"a63f027e-1407-4124-9d2d-0293c1fcf9e2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PeftModelForCausalLM(\n","  (base_model): LoraModel(\n","    (model): Phi3ForCausalLM(\n","      (model): Phi3Model(\n","        (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n","        (embed_dropout): Dropout(p=0.0, inplace=False)\n","        (layers): ModuleList(\n","          (0-31): 32 x Phi3DecoderLayer(\n","            (self_attn): Phi3Attention(\n","              (o_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=3072, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=3072, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (qkv_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=3072, out_features=9216, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=3072, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=9216, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (rotary_emb): Phi3LongRoPEScaledRotaryEmbedding()\n","            )\n","            (mlp): Phi3MLP(\n","              (gate_up_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=3072, out_features=16384, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=3072, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=16384, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (down_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=8192, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=3072, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (activation_fn): SiLU()\n","            )\n","            (input_layernorm): Phi3RMSNorm()\n","            (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n","            (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n","            (post_attention_layernorm): Phi3RMSNorm()\n","          )\n","        )\n","        (norm): Phi3RMSNorm()\n","      )\n","      (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":[],"metadata":{"id":"ygUADnTmWupi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Data collator\n","def data_collator(examples):\n","    return tokenizer.pad(examples, padding=True, return_tensors=\"pt\")\n","\n","# Setup DataLoader\n","train_dataloader = DataLoader(\n","    train_dataset,\n","    batch_size=training_args.per_device_train_batch_size,\n","    shuffle=True,\n","    collate_fn=data_collator\n",")\n","\n","eval_dataloader = DataLoader(\n","    test_dataset,\n","    batch_size=training_args.per_device_eval_batch_size,\n","    collate_fn=data_collator\n",")\n","\n","# Prepare optimizer\n","optimizer = torch.optim.AdamW(lora_model.parameters(), lr=training_args.learning_rate)\n","\n","# Training loop\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","lora_model.to(device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OR37orsjWus6","executionInfo":{"status":"ok","timestamp":1727371748995,"user_tz":-480,"elapsed":547,"user":{"displayName":"Kunal R R","userId":"08771470267005146834"}},"outputId":"47c70c6e-dff2-45b9-ec6d-85bb0fc6c4ce"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PeftModelForCausalLM(\n","  (base_model): LoraModel(\n","    (model): Phi3ForCausalLM(\n","      (model): Phi3Model(\n","        (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n","        (embed_dropout): Dropout(p=0.0, inplace=False)\n","        (layers): ModuleList(\n","          (0-31): 32 x Phi3DecoderLayer(\n","            (self_attn): Phi3Attention(\n","              (o_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=3072, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=3072, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (qkv_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=3072, out_features=9216, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=3072, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=9216, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (rotary_emb): Phi3LongRoPEScaledRotaryEmbedding()\n","            )\n","            (mlp): Phi3MLP(\n","              (gate_up_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=3072, out_features=16384, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=3072, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=16384, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (down_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=8192, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=3072, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (activation_fn): SiLU()\n","            )\n","            (input_layernorm): Phi3RMSNorm()\n","            (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n","            (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n","            (post_attention_layernorm): Phi3RMSNorm()\n","          )\n","        )\n","        (norm): Phi3RMSNorm()\n","      )\n","      (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":[],"metadata":{"id":"YY1wturXWuvy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lora_model.train()\n","for epoch in range(int(training_args.num_train_epochs)):\n","    total_loss = 0\n","    for step, batch in enumerate(tqdm(train_dataloader, desc=f\"Epoch {epoch+1}\")):\n","        batch = {k: v.to(device) for k, v in batch.items()}\n","\n","        optimizer.zero_grad()\n","\n","        outputs = lora_model(**batch)\n","        loss = outputs.loss\n","        total_loss += loss.item()\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        if step % 100 == 0:\n","            avg_loss = total_loss / (step + 1)\n","            wandb.log({\"train_loss\": avg_loss, \"epoch\": epoch, \"step\": step})\n","\n","    # Evaluation\n","    lora_model.eval()\n","    eval_loss = 0\n","    with torch.no_grad():\n","        for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n","            batch = {k: v.to(device) for k, v in batch.items()}\n","            outputs = lora_model(**batch)\n","            eval_loss += outputs.loss.item()\n","\n","    avg_eval_loss = eval_loss / len(eval_dataloader)\n","    wandb.log({\"eval_loss\": avg_eval_loss, \"epoch\": epoch})\n","\n","    lora_model.train()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":495,"referenced_widgets":["98c0cb39ea9f4f719fccd1472ebc599e","9b6483098ab34a12bf4203fb3c0f3b26","5f72caca4411420aae47e8be44cfa46e","f5c322cdee064a298b0d45a3e74f3a9d","799bb9bec3b94df7adb78bcac4a7853e","c00817e3b2d04889b7f4ca787413173e","35fd9c25fd224288a7bba7d8004ad799","31f8b64a75014c718f97e8ece2d39376","46a5729e900e4acfb556dd9302bb23e0","1345754ab07740e38f286960bafd750d","a47d53f1953e4a8d824eb5a4acee0d8a"]},"id":"QaGDuOOoWuyh","executionInfo":{"status":"error","timestamp":1727371781058,"user_tz":-480,"elapsed":5172,"user":{"displayName":"Kunal R R","userId":"08771470267005146834"}},"outputId":"726a08a0-34cb-4b47-c813-7aa57131ea7b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Epoch 1:   0%|          | 0/1093 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98c0cb39ea9f4f719fccd1472ebc599e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","WARNING:transformers_modules.microsoft.Phi-3.5-mini-instruct.af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0.modeling_phi3:`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\n","WARNING:transformers_modules.microsoft.Phi-3.5-mini-instruct.af0dfb8029e8a74545d0736d30cb6b58d2f0f3f0.modeling_phi3:You are not running the flash-attention implementation, expect numerical differences.\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"element 0 of tensors does not require grad and does not have a grad_fn","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-39-0f292cf6ef26>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             )\n\u001b[0;32m--> 521\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    770\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"]}]},{"cell_type":"code","source":[],"metadata":{"id":"iNO1PPwdWu1Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ta4g6g71Wu4K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"TnIpSMT0Wu7G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"oGEGAuxZWu-M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-wAabB6xWvCq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"10zLuGnnWvFt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Wc9ZoJYVWvIc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"DQrSnOFtWvLi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"MB4fmQfPWvOF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JSIBf4xoVYmJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"GE_0vy4zVWZg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define QLoRA Config\n","target_modules = []\n","for i in range(10):\n","    target_modules.extend([\n","        f'model.layers.{i}.self_attn.o_proj',\n","        f'model.layers.{i}.self_attn.qkv_proj',\n","        f'model.layers.{i}.mlp.gate_up_proj',\n","        f'model.layers.{i}.mlp.down_proj',\n","    ])\n","\n","config = LoraConfig(\n","    r=32,\n","    lora_alpha=32,\n","    target_modules=target_modules,\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\"\n",")\n","\n","# Get PEFT model\n","lora_model = get_peft_model(model, config)\n","\n","# Ensure all parameters require gradients\n","for param in lora_model.parameters():\n","    param.requires_grad = True\n","\n","# Print trainable parameters\n","def print_trainable_parameters(model):\n","    trainable_params = 0\n","    all_param = 0\n","    for _, param in model.named_parameters():\n","        all_param += param.numel()\n","        if param.requires_grad:\n","            trainable_params += param.numel()\n","    print(\n","        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n","    )\n","\n","print_trainable_parameters(lora_model)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"f_fJyXJhSjw6","executionInfo":{"status":"error","timestamp":1727370493736,"user_tz":-480,"elapsed":580,"user":{"displayName":"Kunal R R","userId":"08771470267005146834"}},"outputId":"130f2793-0cef-407b-8ba1-54886717b43f"},"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"only Tensors of floating point and complex dtype can require gradients","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-f5fc2f260eef>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Ensure all parameters require gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlora_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Print trainable parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: only Tensors of floating point and complex dtype can require gradients"]}]}]}